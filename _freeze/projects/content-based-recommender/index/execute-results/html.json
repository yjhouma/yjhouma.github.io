{
  "hash": "41986b39eb5c246d4e1fa65bda92917e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Creating a Content-based Recommender System\nauthor: \"Yohanes Jhouma Parulian N\"\ndate: \"2024-06-15\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    toc-title: \"On this page\"\n    toc-depth: 3\n---\n\n\n\n\n\n\n# Libraries for this project\n\n::: {#016c31a7 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pandas as pd\nimport numpy as np\nimport json\n```\n:::\n\n\n# Introduction\n\nHave you ever had a friend ask you to recommend a movie or song based on something they just watched or listened to? It's pretty common, right? You think about what they might like, considering their taste, and suggest something similar. That's basically what a recommender system does, but with a lot more data and a bit more sophistication.\n\nRecommender systems are like your personal assistant, suggesting things you might like based on your preferences and behavior. They're everywhere: Netflix suggests movies, Spotify recommends songs, and Amazon points you to products you might want to buy.\n\nIn general, there are three types od recommender systems:\n\n1. **Content-Based**. Imagine you just watched a movie with your favorite genre. A content-based system would suggest other movies with similar genres and plot.\n\n2. **Collaborative Filtering**. Think of Netflix or Spotify, where you get recommendations based on what other users with similar tastes liked.\n\n3. **Hybrid**. Like the name suggests, this recommender system combine both content-based and colaborative filtering to give a more accurate suggestions.\n\n\nIn this project, we're building a content-based recommender system using the TMDB 5000 dataset. We'll create a system that can suggest movies based on their content.\n\n# Dataset\n\nFor this project, we're using the TMDB 5000 dataset, which is a collection of movie information gathered from [The Movie Database (TMDB)](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata). This dataset provides a wealth of details about movies, including metadata like titles, genres, plot summaries, cast and crew, release dates, and user ratings.\n\n\n\n## Structure of the Dataset\nThe TMDB 5000 dataset consists of two main files:\n\n1. **movies_metadata.csv**: Contains metadata for each movie, including title, genres, overview, release date, and more.\n2. **credits.csv**: Contains information about the cast and crew for each movie.\n\n\n### Movies Metadata\n\n::: {#a4920dbf .cell execution_count=2}\n``` {.python .cell-code}\nmovies_metadata_df = pd.read_csv('data/tmdb_5000_movies.csv')\nmovies_metadata_df.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n(4803, 20)\n```\n:::\n:::\n\n\n::: {#5f0eeea1 .cell execution_count=3}\n``` {.python .cell-code}\nmovies_metadata_df.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>keywords</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>production_companies</th>\n      <th>production_countries</th>\n      <th>release_date</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>237000000</td>\n      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n      <td>http://www.avatarmovie.com/</td>\n      <td>19995</td>\n      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n      <td>en</td>\n      <td>Avatar</td>\n      <td>In the 22nd century, a paraplegic Marine is di...</td>\n      <td>150.437577</td>\n      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n      <td>2009-12-10</td>\n      <td>2787965087</td>\n      <td>162.0</td>\n      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n      <td>Released</td>\n      <td>Enter the World of Pandora.</td>\n      <td>Avatar</td>\n      <td>7.2</td>\n      <td>11800</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300000000</td>\n      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n      <td>http://disney.go.com/disneypictures/pirates/</td>\n      <td>285</td>\n      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n      <td>en</td>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>Captain Barbossa, long believed to be dead, ha...</td>\n      <td>139.082615</td>\n      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n      <td>2007-05-19</td>\n      <td>961000000</td>\n      <td>169.0</td>\n      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n      <td>Released</td>\n      <td>At the end of the world, the adventure begins.</td>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>6.9</td>\n      <td>4500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>245000000</td>\n      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n      <td>http://www.sonypictures.com/movies/spectre/</td>\n      <td>206647</td>\n      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n      <td>en</td>\n      <td>Spectre</td>\n      <td>A cryptic message from Bondâ€™s past sends him o...</td>\n      <td>107.376788</td>\n      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n      <td>2015-10-26</td>\n      <td>880674609</td>\n      <td>148.0</td>\n      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n      <td>Released</td>\n      <td>A Plan No One Escapes</td>\n      <td>Spectre</td>\n      <td>6.3</td>\n      <td>4466</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Movies Credit\n\n::: {#e51f1d6b .cell execution_count=4}\n``` {.python .cell-code}\nmovies_credit_df = pd.read_csv('data/tmdb_5000_credits.csv')\nmovies_credit_df.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n(4803, 4)\n```\n:::\n:::\n\n\n::: {#bf2da81a .cell execution_count=5}\n``` {.python .cell-code}\nmovies_credit_df.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>cast</th>\n      <th>crew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19995</td>\n      <td>Avatar</td>\n      <td>[{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...</td>\n      <td>[{\"credit_id\": \"52fe48009251416c750aca23\", \"de...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>285</td>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>[{\"cast_id\": 4, \"character\": \"Captain Jack Spa...</td>\n      <td>[{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>206647</td>\n      <td>Spectre</td>\n      <td>[{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...</td>\n      <td>[{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Data Preprocessing\n\n::: {#fb2d45d4 .cell execution_count=6}\n``` {.python .cell-code}\nmovies_metadata_df.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4803 entries, 0 to 4802\nData columns (total 20 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   budget                4803 non-null   int64  \n 1   genres                4803 non-null   object \n 2   homepage              1712 non-null   object \n 3   id                    4803 non-null   int64  \n 4   keywords              4803 non-null   object \n 5   original_language     4803 non-null   object \n 6   original_title        4803 non-null   object \n 7   overview              4800 non-null   object \n 8   popularity            4803 non-null   float64\n 9   production_companies  4803 non-null   object \n 10  production_countries  4803 non-null   object \n 11  release_date          4802 non-null   object \n 12  revenue               4803 non-null   int64  \n 13  runtime               4801 non-null   float64\n 14  spoken_languages      4803 non-null   object \n 15  status                4803 non-null   object \n 16  tagline               3959 non-null   object \n 17  title                 4803 non-null   object \n 18  vote_average          4803 non-null   float64\n 19  vote_count            4803 non-null   int64  \ndtypes: float64(3), int64(4), object(13)\nmemory usage: 750.6+ KB\n```\n:::\n:::\n\n\n::: {#5e5b1664 .cell execution_count=7}\n``` {.python .cell-code}\nmovies_credit_df.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4803 entries, 0 to 4802\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   movie_id  4803 non-null   int64 \n 1   title     4803 non-null   object\n 2   cast      4803 non-null   object\n 3   crew      4803 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 150.2+ KB\n```\n:::\n:::\n\n\n### Combining both tables\n\n::: {#3c98046b .cell execution_count=8}\n``` {.python .cell-code}\nmovies_df = movies_metadata_df.merge(movies_credit_df.drop('title',axis=1),left_on='id',right_on='movie_id', how='left').drop('movie_id', axis=1)\n```\n:::\n\n\n## Handling missing value\n\nAs can be seen in the previous chunk of code, there are some columns with missing values. Generally, we need to handle these missing values. In this case, we are lucky because most of the missing values are not directly related to the content of the movie. For example, the homepage is unlikely to be a significant factor when recommending a movie.\n\nOn the other hand, the overview column contains a summary of the movie's plot, which is crucial for our recommendation system. Therefore, we need to handle missing values in this column carefully.\n\nFor now, we will ignore missing values in columns that do not directly impact the movie content and drop rows with missing values in crucial columns like overview.\n\nAlthough tagline can contains information crucial for the content, we choose not to drop rows with missing values in the tagline column. The tagline is a more condensed version of the information in the overview, meaning its information is already covered by the overview. Therefore, the absence of a tagline does not significantly impact our ability to recommend movies based on their content. Additionally not all movie have a tagline.\n\n::: {#5a362e2c .cell execution_count=9}\n``` {.python .cell-code}\nmovies_df = movies_df[~movies_df['overview'].isna()].reset_index(drop=True)\n```\n:::\n\n\n::: {#8248ce14 .cell execution_count=10}\n``` {.python .cell-code}\nmovies_df.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4800 entries, 0 to 4799\nData columns (total 22 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   budget                4800 non-null   int64  \n 1   genres                4800 non-null   object \n 2   homepage              1712 non-null   object \n 3   id                    4800 non-null   int64  \n 4   keywords              4800 non-null   object \n 5   original_language     4800 non-null   object \n 6   original_title        4800 non-null   object \n 7   overview              4800 non-null   object \n 8   popularity            4800 non-null   float64\n 9   production_companies  4800 non-null   object \n 10  production_countries  4800 non-null   object \n 11  release_date          4799 non-null   object \n 12  revenue               4800 non-null   int64  \n 13  runtime               4800 non-null   float64\n 14  spoken_languages      4800 non-null   object \n 15  status                4800 non-null   object \n 16  tagline               3959 non-null   object \n 17  title                 4800 non-null   object \n 18  vote_average          4800 non-null   float64\n 19  vote_count            4800 non-null   int64  \n 20  cast                  4800 non-null   object \n 21  crew                  4800 non-null   object \ndtypes: float64(3), int64(4), object(15)\nmemory usage: 825.1+ KB\n```\n:::\n:::\n\n\n# Exploratory Data Analysis\n\nSince we have a content-based recommender system in mind, we will explore the data that contains information about the content of the movie. Imagine that your friend comes to you and says, \"I've just watched The Dark Knight and I love it. Do you know any other movies like that?\" There are several factors you can consider to give your friend recommendations:\n\n1. **The Genre**. Maybe your friend likes action-packed movies or superhero movies. Considering this, you can recommend other action or superhero movies.\n\n2. **Keywords of the Movie**. This movie might have some keywords attached to it, like DC Comics, superhero, Batman. Considering this, you can recommend not only random superhero movies but something like Superman or Wonder Woman that share the same keywords.\n\n3. **The Plot**. Maybe your friend is interested in movies with similar plots. A movie where the hero has to save a city from a terrorist attack, for example.\n\n4. **The Director**. Each movie director has their own style. Maybe your friend is more interested in the style of Christopher Nolan.\n\n\nConsidering all these factors and many others is the key to making a reliable recommender system.\n\n\n\n## Exploring Genre\n\n### How many Genre a movie have?\n\n::: {#25282188 .cell execution_count=11}\n``` {.python .cell-code}\nmovies_df['genres'].apply(lambda x: len(json.loads(x))).describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\ncount    4800.000000\nmean        2.532708\nstd         1.120651\nmin         0.000000\n25%         2.000000\n50%         2.000000\n75%         3.000000\nmax         7.000000\nName: genres, dtype: float64\n```\n:::\n:::\n\n\n::: {#68cdd9f5 .cell execution_count=12}\n``` {.python .cell-code}\nmovies_df['genres'].apply(lambda x: len(json.loads(x))).value_counts().sort_index().plot.bar()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=583 height=430}\n:::\n:::\n\n\nAs can be seen in the description and the plot, a movie can have a range of 0-7 genres. A movie with 0 genres can be considered as a movie for which we don't know the genre. From the visualization, we can see that most movies have 2 to 3 genres associated with them.\n\n### Genre Distribution\n\n::: {#536e47f5 .cell execution_count=13}\n``` {.python .cell-code}\ndef create_genre_list(x):\n    genre_movie = []\n    jdata = json.loads(x)\n    for d in jdata:\n        genre_movie.append(d['name'])\n    return genre_movie\n\n\ngenre_series = []\n\nfor i, r in movies_df.iterrows():\n    genre_series += create_genre_list(r['genres'])\n\ngenre_series = pd.Series(genre_series)\n```\n:::\n\n\n::: {#cd87284e .cell execution_count=14}\n``` {.python .cell-code}\ngenre_series.value_counts().plot.bar()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=583 height=497}\n:::\n:::\n\n\n::: {#9c6bd18f .cell execution_count=15}\n``` {.python .cell-code}\nlen(genre_series.value_counts())\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n20\n```\n:::\n:::\n\n\nWe can see there are 20 genres recorded in total. From these 20 genres, the most common one is drama. However, keep in mind that what makes a movie unique is not just a single genre but combinations of genres. For example, an Action-Comedy movie will have a very different tone from an Action-Mystery movie. Therefore, it is important to maintain this connection later when we create our recommender system.\n\n## Exploring Keywords\n\n### Numbers of Keywords in a movie\n\n::: {#f6aaf046 .cell execution_count=16}\n``` {.python .cell-code}\nmovies_df['keywords'].apply(lambda x: len(json.loads(x))).describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\ncount    4800.000000\nmean        7.538750\nstd         6.280662\nmin         0.000000\n25%         3.000000\n50%         6.000000\n75%        11.000000\nmax        97.000000\nName: keywords, dtype: float64\n```\n:::\n:::\n\n\n::: {#071a4d58 .cell execution_count=17}\n``` {.python .cell-code}\nmovies_df['keywords'].apply(lambda x: len(json.loads(x))).value_counts().sort_index().plot.bar()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=575 height=433}\n:::\n:::\n\n\nUnlike genres, a movie can have a lot more keywords associated with it. In our database, it can range up to 97 keywords, with a median of 6. This means half of the movies have at least 6 keywords attached to them. \n\n## How many keywords there are\n\n::: {#53e30259 .cell execution_count=18}\n``` {.python .cell-code}\nkeywords = []\nfor i,r in movies_df.iterrows():\n    jdata = json.loads(r['keywords'])\n    for d in jdata:\n        keywords.append(d['name'])\n\nkeywords = pd.Series(keywords)\n```\n:::\n\n\n::: {#ecf2f928 .cell execution_count=19}\n``` {.python .cell-code}\nlen(keywords.unique())\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n9808\n```\n:::\n:::\n\n\n::: {#652f490e .cell execution_count=20}\n``` {.python .cell-code}\nkeywords.value_counts().describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\ncount    9808.000000\nmean        3.689437\nstd         9.669485\nmin         1.000000\n25%         1.000000\n50%         1.000000\n75%         3.000000\nmax       324.000000\nName: count, dtype: float64\n```\n:::\n:::\n\n\nThe total number of keywords available is 9808, however, only a quarter of them appear in at least three different movies. We can keep this in mind, since a keyword that appears only in one or two movies will not provide much information for the recommender system.\n\n## Exploring Overview/The plot description\n\n### How many words contained in an overview?\n\n::: {#f0cf8650 .cell execution_count=21}\n``` {.python .cell-code}\nmovies_df['overview'].apply(lambda x: len(x.split())).describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\ncount    4800.000000\nmean       52.157292\nstd        27.867016\nmin         0.000000\n25%        30.000000\n50%        48.000000\n75%        67.000000\nmax       175.000000\nName: overview, dtype: float64\n```\n:::\n:::\n\n\n::: {#fc87385f .cell execution_count=22}\n``` {.python .cell-code}\nmovies_df['overview'].apply(lambda x: len(x.split())).hist()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){width=583 height=411}\n:::\n:::\n\n\n::: {#1b0a57ff .cell execution_count=23}\n``` {.python .cell-code}\nmovies_df[movies_df['overview'].apply(lambda x: len(x.split())) == 0]\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>keywords</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>production_companies</th>\n      <th>...</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>cast</th>\n      <th>crew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4399</th>\n      <td>0</td>\n      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...</td>\n      <td>NaN</td>\n      <td>43630</td>\n      <td>[]</td>\n      <td>en</td>\n      <td>The Helix... Loaded</td>\n      <td></td>\n      <td>0.0206</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0</td>\n      <td>97.0</td>\n      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n      <td>Rumored</td>\n      <td>NaN</td>\n      <td>The Helix... Loaded</td>\n      <td>4.8</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 22 columns</p>\n</div>\n```\n:::\n:::\n\n\nAs can be seen that the range of overview length is between 0 to 175. Remember that we've drop a movie with no overview. It seems like there are still a movie that don't have an overview. Since it's only one movie i think it is fair to also drop this movie\n\n::: {#b75046ed .cell execution_count=24}\n``` {.python .cell-code}\nmovies_df = movies_df[movies_df['overview'].apply(lambda x: len(x.split())) > 0].reset_index(drop=True)\n```\n:::\n\n\n## Exploring Director\n\n### Extracting Director from the Crew\n\n::: {#afae3e28 .cell execution_count=25}\n``` {.python .cell-code}\ndef return_director(x):\n\n    jdata = json.loads(x)\n    for d in jdata:\n        if d['job'] == 'Director':\n            return d['name']\n    \n    return ''\n```\n:::\n\n\n::: {#ffb4abb1 .cell execution_count=26}\n``` {.python .cell-code}\nmovies_df['crew'].apply(return_director).value_counts().describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\ncount    2347.000000\nmean        2.044738\nstd         2.173457\nmin         1.000000\n25%         1.000000\n50%         1.000000\n75%         2.000000\nmax        29.000000\nName: count, dtype: float64\n```\n:::\n:::\n\n\n::: {#d43884c4 .cell execution_count=27}\n``` {.python .cell-code}\nmovies_df['crew'].apply(return_director).value_counts()[:20].plot.bar()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-28-output-1.png){width=566 height=555}\n:::\n:::\n\n\n::: {#1c19ea88 .cell execution_count=28}\n``` {.python .cell-code}\nmovies_df['director'] = movies_df['crew'].apply(return_director)\n```\n:::\n\n\nThere are 2346 director recorded in the data, however the majority of them only have one movie directed by them. With the same logic as keywords, we need to keep in mind that the director with only few movies will not enrich our recommender system\n\n# Feature Engineering\n\n## Considering Ranking and Scoring\n\nWhen you recommend something to someone, you usually rank options based on how well they match what the person likes. In recommender systems, we do the same by calculating a score for each item. This score tells us how relevant each item is to the user's interests, and we use these scores to rank the items.\n\nIn a recommender system, feature engineering is all about transforming raw data into something meaningful that can be used to make recommendations. Considering scoring in recommender systems, we need to transform all the content we have into something that can be quantified. In other words, we have to extract the features into vectors that we can calculate the similarities.\n\n## Genres\n\nFor our genres, we want to make a vector representation that considers that a movie can have more than one genre. Since there are only 20 genres available, it is reasonable for us to use a binary vector.\n\nFor example, if there are three genres only: Action, Drama, and Comedy:\n* A movie with Action-Drama genres will be represented with 1 1 0.\n* A movie with Drama-Comedy genres will be represented with 0 1 1.\n\n::: {#da0c3252 .cell execution_count=29}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\ndef extract_genre(X):\n    genre_matrix = []\n    for d in X:\n        row_genres = []\n        jdata = json.loads(d)\n        for j in jdata:\n            row_genres.append(j['name'])\n        genre_matrix.append(row_genres)\n\n    return genre_matrix\n\ngenre_extractor = FunctionTransformer(extract_genre)\n```\n:::\n\n\n::: {#15520830 .cell execution_count=30}\n``` {.python .cell-code}\ngenre_vectorizer = CountVectorizer(analyzer= lambda x: x, binary=True)\n\ngenre_matrix = genre_vectorizer.fit_transform(genre_extractor.fit_transform(movies_df['genres'])).toarray()\n```\n:::\n\n\n::: {#65d72c3a .cell execution_count=31}\n``` {.python .cell-code}\ngenre_matrix\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\narray([[1, 1, 0, ..., 0, 0, 0],\n       [1, 1, 0, ..., 0, 0, 0],\n       [1, 1, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\n```\n:::\n:::\n\n\n## Keywords\n\nWe're using TF-IDF (Term Frequency-Inverse Document Frequency) to convert keywords into vectors. TF-IDF helps capture the importance of each keyword by balancing how often a keyword appears in a movie against how common it is across all movies. This way, unique keywords for specific movies get more weight, while common ones get less.\n\nSince we know that most keywords appear only once or twice, we won't need to map those keywords to the vector. This can reduce our dimensionality significantly without losing much information. For now, we will map only keywords that appear at least 5 times.\n\n::: {#d074481c .cell execution_count=32}\n``` {.python .cell-code}\ndef extract_keywords(X):\n    keywords_matrix = []\n    for d in X:\n        row_keywords = []\n        jdata = json.loads(d)\n        for j in jdata:\n            row_keywords.append(j['name'])\n        keywords_matrix.append(row_keywords)\n\n    return keywords_matrix\n\nkeywords_extractor = FunctionTransformer(extract_keywords)\n```\n:::\n\n\n::: {#31cb3390 .cell execution_count=33}\n``` {.python .cell-code}\nkeywords_vectorizer = TfidfVectorizer(analyzer= lambda x: x, min_df=5, binary=True)\nkeywords_matrix = keywords_vectorizer.fit_transform(keywords_extractor.fit_transform(movies_df['keywords'])).toarray()\n```\n:::\n\n\n::: {#8e481988 .cell execution_count=34}\n``` {.python .cell-code}\nkeywords_matrix\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n```\n:::\n:::\n\n\n## Overview\n\nFor plot overviews, we will use Sentence-BERT (SBERT) to create embeddings. Sentence Transformers, based on the SBERT architecture, allow us to convert text into high-dimensional vectors that capture the semantic meaning of the text.\n\nUnlike simple TF-IDF, SBERT captures the deeper semantic meaning of the text, understanding the context and relationships between words. SBERT is particularly effective for longer texts like plot overviews, providing a more nuanced representation than TF-IDF.\nUsing SBERT embeddings for plot overviews helps us create rich, meaningful representations of the movie plots, enhancing the quality of our recommendations.\n\n::: {#4db64dc7 .cell execution_count=35}\n``` {.python .cell-code}\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sentence_transformers import SentenceTransformer\n\n\nclass SbertTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, model_name=\"all-MiniLM-L6-v2\") -> None:\n        self.model_name =model_name\n        self.model = SentenceTransformer(model_name)\n    \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return self.model.encode(X.str.lower())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/opt/homebrew/Caskroom/miniforge/base/envs/forecasting/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning:\n\nUsing `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n\n```\n:::\n:::\n\n\n::: {#3cc9db1c .cell execution_count=36}\n``` {.python .cell-code}\noverview_embedder = SbertTransformer() # Using small model\noverview_embeddings = overview_embedder.fit_transform(movies_df['overview'])\n```\n:::\n\n\n::: {#3ad9be7b .cell execution_count=37}\n``` {.python .cell-code}\noverview_embeddings.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\n(4799, 384)\n```\n:::\n:::\n\n\n## Director\n\nWe can use similar logic as keywords and genres to vectorize director information. Since director with a few movie wont help us much in term of recommendation, we will use only director with more than 4 movie to vectorize. Due to the fact a movie can only have one director we will be usinng binary representation instead of tfidf\n\n::: {#bcd8f626 .cell execution_count=38}\n``` {.python .cell-code}\nmovies_df['director']\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n0           James Cameron\n1          Gore Verbinski\n2              Sam Mendes\n3       Christopher Nolan\n4          Andrew Stanton\n              ...        \n4794     Robert Rodriguez\n4795         Edward Burns\n4796          Scott Smith\n4797          Daniel Hsia\n4798     Brian Herzlinger\nName: director, Length: 4799, dtype: object\n```\n:::\n:::\n\n\n::: {#3ed7be3d .cell execution_count=39}\n``` {.python .cell-code}\ndirector_vectorizer = CountVectorizer(analyzer= lambda x: [x] if x != '' else [], binary=True, min_df=5)\n\n\ndirector_matrix = director_vectorizer.fit_transform(movies_df['director']).toarray()\n```\n:::\n\n\n::: {#b3b3dab6 .cell execution_count=40}\n``` {.python .cell-code}\ndirector_matrix.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\n(4799, 211)\n```\n:::\n:::\n\n\n## Putting it Together\n\n::: {#16ce3ffc .cell execution_count=41}\n``` {.python .cell-code}\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n```\n:::\n\n\n### Creating Pipeline for Feature Extraction\n\n::: {#8c6c6b85 .cell execution_count=42}\n``` {.python .cell-code}\n# Pipeline for Genre Feature Extraction\n\ngenre_pipeline = Pipeline([\n    ('genre_extractor', FunctionTransformer(extract_genre)),\n    ('genre_vectorizer', CountVectorizer(analyzer= lambda x: x, binary=True))\n])\n\n\n# Pipeline for Keywords Feature Extraction\n\nkeywords_pipeline = Pipeline([\n    ('keywords_extractor', FunctionTransformer(extract_keywords)),\n    ('keywords_vectorizer', TfidfVectorizer(analyzer= lambda x: x, min_df=5, binary=True))\n])\n```\n:::\n\n\n### Joining all feature\n\n::: {#3c482fac .cell execution_count=43}\n``` {.python .cell-code}\nfeature_extractor = ColumnTransformer([\n    ('genres_pipeline', genre_pipeline, \"genres\"),\n    ('keywords_pipeline', keywords_pipeline, \"keywords\"),\n    ('overview_pipeline', SbertTransformer(), \"overview\"),\n    ('director_pipeline', CountVectorizer(analyzer= lambda x: [x] if x != '' else [], binary=True, min_df=5), \"director\")\n])\n```\n:::\n\n\n::: {#2f97f2c6 .cell execution_count=44}\n``` {.python .cell-code}\nfeature_matrix = feature_extractor.fit_transform(movies_df).toarray()\n```\n:::\n\n\n::: {#08d1e9d9 .cell execution_count=45}\n``` {.python .cell-code}\nfeature_matrix\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\narray([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n```\n:::\n:::\n\n\n# Build a Recommender System\n\nRemember that I mentioned about scoring and ranking. Now in order to actually recommend a movie, we need to score their similirarity to each other. There are several ways to do this, but the most common one for data involving text is **Cosine Similarity**.\n\nCosine similarity measures how similar two items are by looking at the angle between their vectors. Think of it as comparing the direction of two arrows, regardless of their length. If the arrows point in the same direction, they're similar. In addition to that, It's quick and can handle lots of data without much fuss.\n\n::: {#0753f83b .cell execution_count=46}\n``` {.python .cell-code}\nmovies_list = movies_df[['id','original_title']].copy()\n```\n:::\n\n\n::: {#f32fcdda .cell execution_count=47}\n``` {.python .cell-code}\nsimilarity_matrix = cosine_similarity(feature_matrix, feature_matrix)\n```\n:::\n\n\n::: {#733a6e22 .cell execution_count=48}\n``` {.python .cell-code}\ndef find_similar_movie_using_similarity(movie_id: int):\n    indx = movies_list[movies_list['id'] == movie_id].index.tolist()[0]\n    top_similar = sorted(list(enumerate(similarity_matrix[indx])), key=lambda x: x[1], reverse=True)[1:11]\n    recommended_movies = movies_list.iloc[[t[0] for t in top_similar]].copy()\n    recommended_movies['similarity_score'] = [t[1] for t in top_similar]\n    return recommended_movies\n```\n:::\n\n\n## Running the Recommender Function\n\nNow let's use this recommender system to recommend movies to our friend who just watched Batman Begins.\n\n::: {#c91f5d73 .cell execution_count=49}\n``` {.python .cell-code}\nmovies_list[movies_list['original_title'].str.contains('Batman')]\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>original_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>209112</td>\n      <td>Batman v Superman: Dawn of Justice</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>272</td>\n      <td>Batman Begins</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>415</td>\n      <td>Batman &amp; Robin</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>414</td>\n      <td>Batman Forever</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>364</td>\n      <td>Batman Returns</td>\n    </tr>\n    <tr>\n      <th>1359</th>\n      <td>268</td>\n      <td>Batman</td>\n    </tr>\n    <tr>\n      <th>3853</th>\n      <td>142061</td>\n      <td>Batman: The Dark Knight Returns, Part 2</td>\n    </tr>\n    <tr>\n      <th>4265</th>\n      <td>2661</td>\n      <td>Batman</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#7ca67f78 .cell execution_count=50}\n``` {.python .cell-code}\nbatman_begins_id = 272\n```\n:::\n\n\n::: {#9945521e .cell execution_count=51}\n``` {.python .cell-code}\nfind_similar_movie_using_similarity(batman_begins_id)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>original_title</th>\n      <th>similarity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65</th>\n      <td>155</td>\n      <td>The Dark Knight</td>\n      <td>0.792444</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49026</td>\n      <td>The Dark Knight Rises</td>\n      <td>0.770914</td>\n    </tr>\n    <tr>\n      <th>3325</th>\n      <td>312113</td>\n      <td>Black November</td>\n      <td>0.663642</td>\n    </tr>\n    <tr>\n      <th>1742</th>\n      <td>254473</td>\n      <td>Brick Mansions</td>\n      <td>0.659899</td>\n    </tr>\n    <tr>\n      <th>4634</th>\n      <td>378237</td>\n      <td>Amidst the Devil's Wings</td>\n      <td>0.630629</td>\n    </tr>\n    <tr>\n      <th>3358</th>\n      <td>22314</td>\n      <td>In Too Deep</td>\n      <td>0.625375</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>7220</td>\n      <td>The Punisher</td>\n      <td>0.624695</td>\n    </tr>\n    <tr>\n      <th>3818</th>\n      <td>34769</td>\n      <td>Defendor</td>\n      <td>0.622456</td>\n    </tr>\n    <tr>\n      <th>3827</th>\n      <td>9516</td>\n      <td>Menace II Society</td>\n      <td>0.612793</td>\n    </tr>\n    <tr>\n      <th>1661</th>\n      <td>9989</td>\n      <td>Antitrust</td>\n      <td>0.607391</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAs can be seen from our algorithm, when asked to recommend movies like \"Batman Begins,\" it recommends \"The Dark Knight\" and \"The Dark Knight Rises,\" which are sequels to the movie. On top of that, we also see movies with some detective and superhero vibes. This indicates that our content-based recommender system is effectively identifying and recommending movies that share significant characteristics with the user's input, thus providing relevant and meaningful suggestions.\n\n# Improving Recomender System\n\nCan we improve this model? Yes. In order to improve a model, we need a strategy to quantify the performance of the model itself. In terms of recommender systems, one common evaluation metric is Precision at K (P@K). Precision at K measures the relevance of the top K recommendations made by the system. It is defined as the proportion of recommended items in the top K set that are relevant.\n\nUnfortunately, our dataset is not ideal for evaluating the recommender system since we don't have the actual user consumption data. Without knowing what movies users have actually watched and liked, we can't accurately measure how well our recommendations match user preferences.\n\nThat being said, there are several strategies to improve the model:\n1. **Give Different Weight to Each Feature:** Currently, we are treating every feature as equally important. Depending on the case, this might not be the most optimal. By adjusting the weights of different features (e.g., giving more importance to plot similarity over genre similarity), we can potentially improve the relevance of our recommendations.\n    \n2. **Add More Relevant Features:** We can incorporate additional features that are relevant to the content of the movie, such as the cast, the director, or even more granular details like the sound engineer. These additional features can provide a richer context for making recommendations.\n\n3. **Combine Content-Based Approach with Collaborative Filtering:** Creating a hybrid recommender system by combining content-based filtering with collaborative filtering can leverage the strengths of both approaches. While content-based filtering focuses on item attributes, collaborative filtering leverages user behavior and preferences. This combination can result in more accurate and personalized recommendations.\n\n# Conclusion\n\n\nBuilding a content-based recommender system using the TMDB 5000 dataset has allowed us to explore various aspects of feature engineering and similarity scoring. By converting genres into binary vectors, using TF-IDF for keywords, and employing SBERT for plot overviews, we created a comprehensive model capable of providing relevant movie recommendations.\n\nOur model, when asked to recommend movies like \"Batman Begins,\" successfully suggested sequels like \"The Dark Knight\" and \"The Dark Knight Rises,\" as well as other movies with similar detective and superhero vibes. This demonstrates the effectiveness of our content-based approach in capturing the nuances of movie content.\n\nHowever, there is always room for improvement. Precision at K (P@K) is a common metric for evaluating recommender systems, but our dataset lacks actual user consumption data, which limits our ability to accurately measure performance.\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}